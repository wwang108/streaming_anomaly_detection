{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFW5dELrjrtx"
      },
      "outputs": [],
      "source": [
        "# Install the boto3 library for AWS interactions\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc7to21mjxvL"
      },
      "outputs": [],
      "source": [
        "# Import boto3 and set up AWS credentials and S3 client for data access\n",
        "import boto3\n",
        "aws_access_key_id = ''\n",
        "aws_secret_access_key = ''\n",
        "\n",
        "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-WSaZIFkVzu"
      },
      "outputs": [],
      "source": [
        "# Set up Weights & Biases (wandb) logging for experiment tracking (optional)\n",
        "from getpass import getpass\n",
        "wandb_logging = True\n",
        "if wandb_logging:\n",
        "    wandb_api_key = getpass(\"Copy your WANDB_API_KEY:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5rwn0NTkg7u"
      },
      "outputs": [],
      "source": [
        "# Install and import wandb for experiment tracking\n",
        "!pip install wandb\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "To8jw_cykwVX"
      },
      "outputs": [],
      "source": [
        "# Initialize a wandb project for logging and tracking the anomaly detection model\n",
        "wandb.init(project=\"anomaly_detection\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-wygQj6j1CT"
      },
      "outputs": [],
      "source": [
        "# Dowload the data\n",
        "bucket_name = 'aws-public-blockchain'\n",
        "date_strings = [\n",
        "    \"2023-10-23\",\n",
        "    \"2023-10-24\",\n",
        "    \"2023-10-25\",\n",
        "    \"2023-10-26\",\n",
        "    \"2023-10-27\",\n",
        "    \"2023-10-28\",\n",
        "    \"2023-10-29\",\n",
        "    \"2023-10-30\"\n",
        "]\n",
        "for date in date_strings:\n",
        "  prefix = f'v1.0/btc/transactions/date={date}/'\n",
        "  response = s3.list_objects_v2(Bucket=bucket_name,  Prefix=prefix)\n",
        "  for item in response.get('Contents', []):\n",
        "      print(item.get('Key'))\n",
        "  file_name = item.get('Key')\n",
        "  s3.download_file(bucket_name, file_name, f'test/{date}.snappy.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDJSjIBgj-Sg"
      },
      "outputs": [],
      "source": [
        "# Choose some columns\n",
        "columns_to_use = ['size', 'virtual_size', 'input_count', 'output_count', 'input_value', 'output_value', 'fee']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZpr5mTvkAUt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "df = pd.read_parquet(f'test/{date}.snappy.parquet')\n",
        "df_dropped = df.dropna()\n",
        "used = df_dropped[columns_to_use]\n",
        "scaler = StandardScaler()\n",
        "np_scaled = scaler.fit_transform( df_dropped[columns_to_use])\n",
        "outliers_fraction=0.05\n",
        "data = pd.DataFrame(np_scaled)\n",
        "model =  IsolationForest(contamination=outliers_fraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ewg3eX_kRrY"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(data)\n",
        "df_dropped['anomaly_IsolationForest'] = pd.Series(model.predict(df_dropped[columns_to_use]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdu5xguWkj6D"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model to a file\n",
        "model_file = \"isolation_forest_model.joblib\"\n",
        "scaler_file = \"scaler.joblib\"\n",
        "joblib.dump(model, model_file)\n",
        "joblib.dump(scaler, scaler_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6zhZ0_Lkope"
      },
      "outputs": [],
      "source": [
        "if wandb_logging:\n",
        "    wandb.login(key=wandb_api_key, relogin=True)\n",
        "else:\n",
        "    logger = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15noo18nkyzb"
      },
      "outputs": [],
      "source": [
        "wandb.save(model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "285xE37Bkzfe"
      },
      "outputs": [],
      "source": [
        "wandb.save(scaler_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
